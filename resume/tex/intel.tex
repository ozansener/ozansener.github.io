 \textbf{Intel Labs}, Munich, Germany \hfill February 2018 \textendash ~ Present \vspace{0.5mm}\\ \vspace{0mm}
   \hspace{-1.5mm} Post-Doctoral Researcher (Feb 2018 - Nov 2019) // Research Scientist (Nov 2019 - Present)  \hfill \vspace{-4mm} \\

Developed a multi-objective optimization-based method for multi-task learning. The resulting method provably finds a Pareto optimal solution of given loss functions \emph{(in NeurIPS 2018)}. Further applied this method to learning universal models from multiple datasets \emph{(in CVPR 2020)}.

Worked on understanding and improving the sample efficiency of transfer learning algorithms. i) Developed large-scale evaluation benchmarks to understand the sample complexity of continual learning \mbox{\emph{(in ICCV 2021)}}. ii) Proposed a theoretical framework for understanding the sample-complexity of meta-learning \emph{(in NeurIPS 2020)}. iii) Improved the sample-complexity of derivative-free optimization by automatically discovering and utilizing the underlying manifold structure \emph{(in ICLR 2020)}.

Mentored three Ph.D. level interns, one post-doctoral researcher, and one research scientist. All projects succeeded with publications in top-tier machine learning and computer vision venues.  