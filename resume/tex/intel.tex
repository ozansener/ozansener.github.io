 \textbf{Intel Labs}, Munich, Germany \hfill February 2018 \textendash ~ Present \vspace{0.5mm}\\ \vspace{0mm}
 \hspace{-1.5mm} Post-Doctoral Researcher  \hfill \vspace{2mm} \\
 Worked on sample efficient deep learning. The key tool to increase sample efficiency of learning algorithms is learning an inductive bias from additional sources. These sources can be privileged information, auxiliary tasks or auxiliary domains. 

Developed a Bayesian deep learning method which can utilize any privileged information while training an arbitrary neural network. Theoretically showed that it is possible to learn with $\mathcal{O}(\frac{1}{n})$ rate (in generalization error sense) using privileged information in oracle. \emph{(in CVPR 2018)}. 

Developed a multi-objective optimization based method for multi-task learning. The resulting method provably finds a Pareto optimal solution of given loss functions \emph{(in NIPS 2018)}.

Developed a domain generalisation method using distributionally robust optimization. The proposed method learns an ensemble of models such that each correspond to different bias variance trade-off. In test time, the developed method selects and uses the right bias-variance trade-off \emph{(in NIPS 2018)}.